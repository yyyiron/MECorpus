{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "maxid——17642803\n",
    "去燥\n",
    "分词(获取中文分词)\n",
    "计算签名(tokens，)\n",
    "海明计算（最快的批量计算方式）如果发现有小于3，即不再计算\n",
    "simhash处理的时候，正则匹配中英文，拆分所有四字短语\n",
    "准确度优化方案：\n",
    "1.拆分短句\n",
    "2.统计短句出现的次数，进行签名计算\n",
    "计算方式：\n",
    "1.从数据库一条条拿数据计算simhash，id，放入redis，修改数据表的持久化状态，否则不做调整\n",
    "2.计算海明距离后，如果相似，记录相似id，并且修改状态\n",
    "3.不相似，不做任何操作\n",
    "\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    " \n",
    "sys.path.append('../../')\n",
    "import time\n",
    "import jieba.analyse\n",
    "import numpy as np\n",
    "jieba.load_userdict(r\"dict1.txt\")\n",
    "str2 = \"\"\"\n",
    "\"\"\"\n",
    "REDIS_SIM_KEY = 'simkey'\n",
    "CHECK_MAX_ID = 'max_id'\n",
    "ID_SIMHASH_MAP = 'id_simhash'\n",
    " \n",
    "class Simhash_worker():\n",
    "    \"\"\"\n",
    "    用来进行分布式文章去重check\n",
    "    \"\"\"\n",
    " \n",
    "    pass\n",
    " \n",
    "def web_content_filter(content):\n",
    "    \"\"\"\n",
    "    只保留汉字\n",
    "    :param content:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    reg = r'[\\u4e00-\\u9fcc]+'\n",
    "    # reg = r'[\\W\\u4e00-\\u9fcc]+'\n",
    "    content = ''.join(re.findall(reg, content))\n",
    "    return content\n",
    " \n",
    "def distance_haiming(hash1, hash2):\n",
    "    t1 = '0b' + str(hash1)\n",
    "    t2 = '0b' + str(hash2)\n",
    "    n = int(t1, 2) ^ int(t2, 2)\n",
    "    i = 0\n",
    "    while n:\n",
    "        n &= (n - 1)\n",
    "        i += 1\n",
    "    return i\n",
    " \n",
    "class SimhashManager:\n",
    "    def __init__(self, content):\n",
    "        self.simhash = self.simhash(content)\n",
    " \n",
    "    def __str__(self):\n",
    "        return str(self.simhash)\n",
    " \n",
    "    def simhash(self, content):\n",
    "        content = web_content_filter(content)\n",
    "        seg = jieba.cut(content)\n",
    "        # jieba.analyse.set_stop_words('stopword')\n",
    "        # jieba.analyse.set_idf_path(r'my_idf')\n",
    "        keyWord = jieba.analyse.extract_tags(\n",
    "            '|'.join(seg), topK=50, withWeight=True, allowPOS=())  # 在这里对jieba的tfidf.py进行了修改\n",
    "        # 将tags = sorted(freq.items(), key=itemgetter(1), reverse=True)修改成tags = sorted(freq.items(), key=itemgetter(1,0), reverse=True)\n",
    "        # 即先按照权重排序，再按照词排序\n",
    "        keyList = []\n",
    "        # print(len(keyWord))\n",
    "        # print(keyWord)\n",
    "        for feature, weight in keyWord:\n",
    "            # weight = int(weight * 100)\n",
    "            feature = self.string_hash(feature)\n",
    "            temp = []\n",
    "            for i in feature:\n",
    "                if (i == '1'):\n",
    "                    temp.append(weight)\n",
    "                else:\n",
    "                    temp.append(-weight)\n",
    "            keyList.append(temp)\n",
    "        list1 = np.sum(np.array(keyList), axis=0)\n",
    "        if (keyList == []):  # 编码读不出来\n",
    "            return '00'\n",
    "        simhash = ''\n",
    "        for i in list1:\n",
    "            if (i > 0):\n",
    "                simhash = simhash + '1'\n",
    "            else:\n",
    "                simhash = simhash + '0'\n",
    "        return simhash\n",
    " \n",
    "    def string_hash(self, source):\n",
    "        if source == \"\":\n",
    "            return 0\n",
    "        else:\n",
    "            x = ord(source[0]) << 7\n",
    "            m = 1000003\n",
    "            mask = 2 ** 128 - 1\n",
    "            for c in source:\n",
    "                x = ((x * m) ^ ord(c)) & mask\n",
    "            x ^= len(source)\n",
    "            if x == -1:\n",
    "                x = -2\n",
    "            x = bin(x).replace('0b', '').zfill(64)[-64:]\n",
    "            return str(x)\n",
    " \n",
    "    def distance(self, com):\n",
    "        t1 = '0b' + self.simhash\n",
    "        t2 = '0b' + com.simhash\n",
    "        n = int(t1, 2) ^ int(t2, 2)\n",
    "        i = 0\n",
    "        while n:\n",
    "            n &= (n - 1)\n",
    "            i += 1\n",
    "        return i\n",
    " \n",
    "    def simhash_by_sentence(self, content):\n",
    "        simhash = ''\n",
    "        return simhash\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    this_simhash1 = str(SimhashManager('高智能电控系统根据操作习惯和操作工况，该系统具有S/P/H不同的动力模式，如高动力举升、低动力行走等，可以让车辆在各种工况下灵活的发挥其的性能，达到最佳的能量使用效率，更加节能和环……'))\n",
    "    this_simhash2 = str(SimhashManager('智能电控系统根据操作习惯和操作工况，该系统具有S/P/H不同的动力模式，如高动力举升、低动力行走等，可以让车辆在各种工况下灵活的发挥其的性能，达到最佳的能量使用效率，更加节能和环……'))\n",
    "    print(\"输出两个测试文本之间的重复指数，低于20即为重复,可灵活调控\")\n",
    "    print(distance_haiming(this_simhash1, this_simhash2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
